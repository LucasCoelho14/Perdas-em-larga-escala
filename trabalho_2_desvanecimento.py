# -*- coding: utf-8 -*-
"""Trabalho 2 - Desvanecimento.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1okqz47iwz3GpsjnwlVtuEd2r378YiS9D

#Trabalho 2 - Desvanecimento

Objetivo: Caracterizar canal sem fio a partir de medidas de campo de Respostas ao Impulso do Canal (CIRs)


Abaixo constam dois arquivos com medições de CIRs obtidas através de uma campanha do NIST descrita em:
https://www.nist.gov/publications/industrial-wireless-systems-radio-propagation-measurements

Os arquivos contém medidas de nível de potência normalizada em função dos atrasos (taps) em ns para diferentes posições da antena receptora. A primeira linha do arquivo constitui nos instantes de atraso e as linhas seguintes são as potências normalizadas pela maior potência recebida.

## Parte I: Encontrar distribuição estatística que melhor modela o ambiente
"""

# Importar tabela
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from google.colab import drive
!pip install marcumq
plt.rcParams.update({
    'font.family': 'serif',
    'mathtext.fontset': 'dejavuserif',

    # Tamanhos de fonte globais
    'font.size': 12,           # Tamanho base
    'axes.titlesize': 16,      # Título do gráfico
    'axes.labelsize': 16,      # Rótulos dos eixos (xlabel, ylabel)
    'xtick.labelsize': 12,     # Ticks do eixo x
    'ytick.labelsize': 12,     # Ticks do eixo y
    'legend.fontsize': 12,     # Legenda
    'figure.titlesize': 16,    # Título da figura (se usar suptitle)
})
# 1. Montar o Google Drive
drive.mount('/content/drive')

# 2. Definir o caminho para o arquivo
# O caminho será '/content/drive/My Drive/' seguido pelo caminho do seu arquivo no Drive.
# Certifique-se de que a capitalização (Trabalhos) está correta.
path = ['/content/drive/My Drive/Trabalhos/cirNTaps8SteamPlant.csv', '/content/drive/My Drive/Trabalhos/cirNTaps20SteamPlant.csv']

def importar_csv(caminho):
    try:
        df = pd.read_csv(caminho)
        print("CSV importado com sucesso!")
        print(df.head())  # Mostra as primeiras 5 linhas para verificação
        return df
    except FileNotFoundError:
        print(f"Erro: O arquivo não foi encontrado no caminho: {caminho}")
    except Exception as e:
        print(f"Ocorreu um erro ao ler o arquivo: {e}")

# Exemplo de uso para dois caminhos diferentes
df_0 = importar_csv(path[0])
df_1 = importar_csv(path[1])
import numpy as np
# 1. Converter o DataFrame do pandas para um array NumPy
data_array_0 = df_0.values
data_array_1 = df_1.values

import numpy as np
# 1. Converter o DataFrame do pandas para um array NumPy
data_array_0 = df_0.values
data_array_1 = df_1.values

"""### **1) Montar sinal potência recebida em função do tempo. Para cada instante de tempo (linha da tabela), somar todas as componentes.**

*A potência $|r(t)|^2$ recebida em algum tempo é descoberta somando-se as potências de caminho múltiplo resolvidas no perfil de atraso de potência em caminho múltiplo instantânea*

$|R(t)|^2 = \sum_{n=0}^{N-1} A_n(t)$, em que $A_n = a_n^2$

####**8 Taps**
"""

N = len(data_array_0[:,0])
P1 = np.empty(N)
# 2. Somar CADA elemento de potência normalizada no array
for i in range(0,N):
    P1[i] = (sum(data_array_0[i]))

plt.figure(figsize=(10, 6))
plt.plot(P1)
plt.title('Soma de potências de caminho múltiplo')
plt.ylabel(r'$|R_1(t_i)|^2$')
#plt.ylabel(r'Potência recebida')
plt.xlabel(r'$i$')
plt.grid()

"""####**20 Taps**"""

N = len(data_array_1[:,0])
P2 = np.empty(N)
# 2. Somar CADA elemento de potência normalizada no array
for i in range(0,N):
    P2[i] = sum(data_array_1[i])

plt.figure(figsize=(10, 6))
plt.plot(P2)
plt.title('Soma de potências de caminho múltiplo')
plt.ylabel(r'$|R_2(t_i)|^2$')
plt.xlabel(r'$i$')
plt.grid()

"""###**2) Verificar se o sinal tem variação da média, i.e. se o sinal tem componentes de perda de percurso e de sombreamento. Caso afirmativo, filtrar estas componentes e deixar o sinal com média nula.**"""

# Filtrar componentes de grande escala (Perda de Percurso + Sombreamento)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.signal import savgol_filter


# R_1 é a envoltória da Potência Recebida Total (|R_1(t_i)|^2)
# Remoção dos zeros que prejudicam a CDF
R_1 = np.sqrt(P1[P1 > 1e-10]) # r_1 = sqrt(|r_1|^2)

# Filtragem com filtro Savgol
window_length = 3001   # ~30% (10530)
polyorder = 3 # ordem do polinômio (2 ou 3 é típico)
R1_filtrado = savgol_filter(R_1, window_length=window_length, polyorder=polyorder)# Aplicar filtro

# Plotagem da Média Móvel
plt.figure(figsize=(10, 6))
plt.plot(R_1, label=r'Sinal original', alpha=0.5)
plt.plot(R1_filtrado, label=f'Sinal filtrado ({window_length} amostras)', color='red', linewidth=2)
plt.ylabel(r'$|R_1(t_i)|$')
plt.xlabel(r'$i$')
plt.title(f'Sinal Recebido e Sinal Filtrado')
plt.legend()
plt.grid(True)
plt.show()

# b. Calcular o Desvanecimento Rápido (Componente com Média Unitária)
# Desvanecimento Rápido (normalizado) |r(t)| = |R(t)| / |R_MM(t)|

r_desvanecimento_rapido = R_1/R1_filtrado #20*np.log10(r0/r_media_movel)
r_desvanecimento_rapido_dB = 20*np.log10(R_1/R1_filtrado)
# Plotagem do Desvanecimento Rápido
plt.figure(figsize=(10, 6))
#plt.plot(r_1, label=r'Sinal original', alpha=0.5)
plt.plot(r_desvanecimento_rapido_dB, label=f'', color='red', linewidth=2)
plt.ylabel(r'$|r_{1}(t_i)|$ (dB)')
plt.xlabel(r'$i$')
plt.title(f'Sinal Recebido Filtrado')
plt.legend()
plt.grid(True)
plt.show()

"""### **3) Plotar Histograma das medidas filtradas.**"""

# c. Plotar Histograma

# Se você modelar a potência (r_desvanecimento_rapido):
plt.figure(figsize=(10, 6))
plt.hist(r_desvanecimento_rapido, bins=500, density=True, edgecolor='black', alpha=0.7)
plt.title('Histograma da Potência de Desvanecimento Rápido')
plt.xlabel(r'$|r_{1}(t_i)|$')
plt.ylabel('Frequência')
plt.grid(axis='y', alpha=0.5)
plt.show()

"""### **4) Plotar CDF das medidas e das distribuições Rayleigh, Rice e Nakagami. Verificar quais parâmetros melhor ajustam as distribuições aos dados. Pode usar a função fit da SciPy, distfit ou qualquer outra biblioteca de sua escolha.**"""

# 4: Ajuste de distribuições e Plotagem da CDF
from scipy import stats
# Garantir que não há valores negativos ou NaN
r_valid = r_desvanecimento_rapido[np.isfinite(r_desvanecimento_rapido)]
#r_valid = np.sqrt(r_valid[r_valid > 0])  # amplitudes e não potência; devem ser positivas
Er2 = np.mean(r_desvanecimento_rapido**2)
rho = np.sort(r_valid)/np.sqrt(Er2)
x = rho #np.sort(r_valid)
# --- Ajuste das distribuições ---
# Rayleigh
params_rayleigh = stats.rayleigh.fit(rho)
# Rice (Rician)
params_rice = stats.rice.fit(rho, floc=0)
b = params_rice[0]          # parâmetro de forma do SciPy
sigma = params_rice[2]      # scale = σ
nu_fisico = b * sigma       # ν = b * σ
k_rice = (b**2) / 2         # fator k de Rice
# Nakagami
params_nakagami = stats.nakagami.fit(rho, floc=0)

# --- Geração da CDF empírica (medidas) ---
empirical_cdf = np.arange(1, len(x)+1) / len(x)

# --- CDFs teóricas ---
#x = np.linspace(min(sorted_data), max(sorted_data), len(r_valid))
cdf_rayleigh = stats.rayleigh.cdf(x, *params_rayleigh)
cdf_rice = stats.rice.cdf(x, *params_rice)
cdf_nakagami = stats.nakagami.cdf(x, *params_nakagami)

# --- Plotagem ---
plt.figure(figsize=(10, 6))
plt.plot(x, empirical_cdf, 'k', lw=2, label='CDF Empírica (Medidas)')
plt.plot(x, cdf_rayleigh, '--', color ='steelblue', lw=2, label=f'Rayleigh\nσ={params_rayleigh[1]:.3f}')
plt.plot(x, cdf_rice, '--', lw=1.5, color ='orange', label=f'Rice\nk={k_rice:.3f}')
plt.plot(x, cdf_nakagami, '--', lw=2, color ='green', label=f'Nakagami\nm={params_nakagami[0]:.3f}')
plt.xlabel(r'$|r_1(t_i)|$')
plt.ylabel('Função Distribuição Cumulativa (CDF)')
plt.title('Ajuste de Distribuições (scipy): Rayleigh, Rice e Nakagami')
plt.legend()
plt.grid(True)
plt.show()

# --- Impressão dos parâmetros ajustados ---
print("Parâmetros estimados:")
print(f"Rayleigh: loc={params_rayleigh[0]:.4f}, scale={params_rayleigh[1]:.4f}")
print(f"Rice: nu={nu_fisico:.4f}, loc={params_rice[1]:.4f}, scale={params_rice[2]:.4f}")
print(f"Nakagami: m={params_nakagami[0]:.4f}, loc={params_nakagami[1]:.4f}, scale={params_nakagami[2]:.4f}")

"""-> Quando existe um componente de sinal estacionário do1ninante (sem atenuação), como um caminho de
propagação na linha de visão, a distribuição de envelope de atenuação em pequena escala é de Ricean.Ricean descreve melhor distribuição de envelope recebido quando existe um sinal dominante (estacionário) com outros sinais fracos de múltiplo percurso.

### **5) Plotar CDFs das medidas e das 3 distribuições de envoltória normalizada ρ conforme descrito no Capítulo 2 da dissertação https://repositorio.unb.br/handle/10482/11357. Usar os estimadores descritos na Seção 4.2 para plotar as distribuições de Rice e Nakagami. Comparar com modelos obtidos na tarefa 4.**
"""

#Rayleigh
#1. Parâmetros. #E[R^2] = E[ak^2] = 2*sigma^2. # Entretanto, E[A^2]= 1 => sigma = 1 / np.sqrt(2), o que não é o que scypi stats encontra. Logo, é preciso aplicar um deslocamento denotado por loc e igual ao mínimo do desvanecimento rápido.
#loc é o deslocamento que faz com que o argumento da distribuição de Rayleigh comece em zero para rho = min(rho)
loc = rho.min()
Er2_desloc= np.mean((rho - loc)**2)
sigma_ray = np.sqrt(Er2_desloc/2) #sigma = np.sqrt(E[ak^2]/2)
# 2. Calcular CDF Rayleigh
cdf_rayleigh_manual = 1 - np.exp(-((rho - loc)**2) / (2*sigma_ray**2))

# Rice
#from scipy.integrate import quad from scipy.special import iv  # iv(nu, x) = I_nu(x) #cdf_rice_manual = np.zeros(len(rho)) for ii in range(len(rho)):
#def Qv(a,b,v):    return x * (x/a)**(v-1) * np.exp(-(x**2+a**2)/2) * iv(v-1, a*x)
import marcumq
#1. Parâmetros
var_rho2 = np.var((rho)**2)
m = 1/var_rho2
k = np.sqrt(m**2-m)/(m - np.sqrt(m**2-m))
# 2. Calcular CDF Rice
v = 1
a = np.sqrt(2*k)
b = np.sqrt(2*(1+k))*rho # variável de Rice em função de rho
Q1 = marcumq.marcumq(v, a, b)
cdf_rice_manual = 1 - Q1

# Nakagami -m
from scipy.special import gamma, gammaincc
#2. Calcular CDF Nakagami
cdf_nakagami_manual = 1 - gammaincc(m, m * rho**2)

plt.figure(figsize=(10, 6))
plt.plot(x, empirical_cdf, 'k', lw=2, label='CDF Empírica (Medidas)')
plt.plot(x, cdf_rayleigh_manual,  '--', color ='steelblue', lw=2, label=f'Rayleigh\nσ={sigma_ray:.3f}')
plt.plot(x, cdf_rice_manual,  '--', color ='orange', lw=1.5, label=f'Rice\nk={k:.3f}')
plt.plot(x, cdf_nakagami_manual, '--', color = 'green', lw=2, label=f'Nakagami\nm={m:.3f}')
plt.xlabel(r'$|r_1(t_i)|$')
plt.ylabel('Função Distribuição Cumulativa (CDF)')
plt.title('Ajuste de Distribuições: Rayleigh, Rice e Nakagami')
plt.legend()
plt.grid(True)
plt.show()

# --- Impressão dos parâmetros ajustados ---
print("Parâmetros estimados:")
print(f"Rayleigh: loc={params_rayleigh[0]:.4f}, scale={params_rayleigh[1]:.4f}")
print(f"Rice: a={a:.4f}, loc={0:.4f}, scale={Er2/np.sqrt(2*(1+k)):.4f}")
print(f"Nakagami: m={m:.4f}, loc={0:.4f}, scale={00:.4f}")

"""### **6) Fazer considerações sobre os valores de parâmetros obtidos.**

Rayleigh:
* Parâmetros idênticos obtidos.
* O desvio padrão obtido para o modelo de Rayleigh, $\sigma = 0,087$, é resultado do deslocamento da distribuição em $\mathrm{loc} = 0,88$ ($\mathrm{min}\{r(t_i)\}$).

Rice:
* É preciso converter parâmetros da biblioteca.
* Ajuste da biblioteca stats ($\mathrm{loc} =  0$) obteve $k = 969$, enquanto o valor calculado foi $k = 956$. Descreve a relação entre a potência do sinal direto e sinal de multipercurso.

Nakagami:
* Ajuste da biblioteca stats ($\mathrm{loc} =  0$) obteve $m = 487$, enquanto o valor calculado foi $m = 479$. Descreve situação de desvanecimento fraco, com forte sinal direto.

### **7) Comparar procedimento para os dois arquivos e analisar a influência da resolução da CIR.**
"""

# 2: Filtrar componentes de grande escala (Perda de Percurso + Sombreamento)
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# r_1 é a envoltória da Potência Recebida Total (|r_1(t_i)|^2)

# a. Calcular a Média Móvel (Média Local / Sombreamento)
# Remoção dos zeros que prejudicam a CDF
R_2 = np.sqrt(P2[P2 > 1e-10]) # r_1 = sqrt(|r_1|^2)
# Savgol_filter Parâmetros
window_length = 2001   # ímpar, ~20% do sinal total (10530 pontos)
polyorder = 3         # ordem do polinômio (2 ou 3 é típico)
R_2_filtrado = savgol_filter(R_2, window_length=window_length, polyorder=polyorder) # Aplicar filtro

# Plotagem da Média Móvel
plt.figure(figsize=(10, 6))
plt.plot(R_2, label=r'Sinal original', alpha=0.5)
plt.plot(R_2_filtrado, label=f'Sinal filtrado ({window_length} amostras)', color='red', linewidth=2)
plt.ylabel(r'$|R_2(t_i)|$')
plt.xlabel(r'$i$')
plt.title(f'Sinal Recebido e Sinal Filtrado')
plt.legend()
plt.grid(True)
plt.show()

# b. Calcular o Desvanecimento Rápido (Componente com Média Unitária)
# Desvanecimento Rápido (normalizado) |r(t)| = |R(t)| / |R_MM(t)|

r_2_desvanecimento_rapido = R_2/R_2_filtrado #20*np.log10(r0/r_media_movel)
r_2_desvanecimento_rapido_dB = 20*np.log10(R_2/R_2_filtrado)
# Plotagem do Desvanecimento Rápido
plt.figure(figsize=(10, 6))
#plt.plot(r_1, label=r'Sinal original', alpha=0.5)
plt.plot(r_2_desvanecimento_rapido_dB, label=f'', color='red', linewidth=2)
plt.ylabel(r'$|r_{2}(t_i)|$ (dB)')
plt.xlabel(r'$i$')
plt.title(f'Sinal Recebido Filtrado pela Média Móvel')
plt.legend()
plt.grid(True)
plt.show()

# c. Plotar Histograma
plt.figure(figsize=(10, 6))
plt.hist(r_2_desvanecimento_rapido, bins=500, density=True, edgecolor='black', alpha=0.7)
plt.title('Histograma da Potência de Desvanecimento Rápido')
plt.xlabel(r'$|r_{2}(t_i)|$')
plt.ylabel('Frequência')
plt.grid(axis='y', alpha=0.5)
plt.show()

# Ajuste de distribuições e Plotagem das CDFs
from scipy import stats

# Garantir que não há valores negativos ou NaN
r_2_valid = r_2_desvanecimento_rapido[np.isfinite(r_2_desvanecimento_rapido)]
#r_valid = np.sqrt(r_valid[r_valid > 0])  # amplitudes e não potência; devem ser positivas
Er2_2 = np.mean(r_2_desvanecimento_rapido**2)
rho2 = np.sort(r_2_valid)/np.sqrt(Er2_2)
x2 = rho2

# --- Ajuste das distribuições ---
# Rayleigh
params_rayleigh2 = stats.rayleigh.fit(r_2_valid)
# Rice (Rician)
params_rice2 = stats.rice.fit(r_2_valid, floc=0)
b2 = params_rice2[0]          # parâmetro de forma do SciPy
sigma2 = params_rice2[2]      # scale = σ
nu_fisico2 = b2 * sigma2       # ν = b * σ
k_rice2 = (b2**2) / 2         # fator de Rice clássico # -
# Nakagami
params_nakagami2 = stats.nakagami.fit(r_2_valid, floc=0)

# --- Obtenção das CDFs ---
# CDF empírica (medidas)
empirical_cdf2 = np.arange(1, len(x2)+1) / len(x2)

# CDFs teóricas
cdf_rayleigh2 = stats.rayleigh.cdf(x2, *params_rayleigh)
cdf_rice2 = stats.rice.cdf(x2, *params_rice)
cdf_nakagami2 = stats.nakagami.cdf(x2, *params_nakagami)

# --- Plotagem ---
plt.figure(figsize=(10, 6))
plt.plot(x2, empirical_cdf2, 'k', lw=2, label='CDF Empírica (Medidas)')
plt.plot(x2, cdf_rayleigh2, '--', lw=2, label=f'Rayleigh\nσ={params_rayleigh2[1]:.3f}')
plt.plot(x2, cdf_rice2, '--', lw=1.5, label=f'Rice\nk={k_rice2:.3f}')
plt.plot(x2, cdf_nakagami2, '--', lw=2, label=f'Nakagami\nm={params_nakagami2[0]:.3f}')
plt.xlabel(r'$|r_2(t_i)|$')
plt.ylabel('Função Distribuição Cumulativa (CDF)')
plt.title('Ajuste de Distribuições (scipy): Rayleigh, Rice e Nakagami')
plt.legend()
plt.grid(True)
plt.show()

# --- Impressão dos parâmetros ajustados ---
print("Parâmetros estimados:")
print(f"Rayleigh: loc={params_rayleigh2[0]:.4f}, scale={params_rayleigh2[1]:.4f}")
print(f"Rice: a={b2:.4f}, loc={params_rice2[1]:.4f}, scale={params_rice2[2]:.4f}")
print(f"Nakagami: m={params_nakagami2[0]:.4f}, loc={params_nakagami2[1]:.4f}, scale={params_nakagami2[2]:.4f}")

#Rayleigh
#1. Parâmetros. #E[R^2] = E[ak^2] = 2*sigma^2. # Entretanto, E[A^2]= 1 => sigma = 1 / np.sqrt(2), o que não é o que scypi stats encontra. Logo, é preciso aplicar um deslocamento denotado por loc e igual ao mínimo do desvanecimento rápido.
#loc é o deslocamento que faz com que o argumento da distribuição de Rayleigh comece em zero para rho = min(rho)
loc_2 = r_2_desvanecimento_rapido.min()
Er2_2_desloc= np.mean((r_2_desvanecimento_rapido - loc_2)**2)
sigma_ray2 = np.sqrt(Er2_2_desloc/2) #sigma = np.sqrt(E[ak^2]/2)
# 2. Calcular CDF Rayleigh
cdf_rayleigh_manual2 = 1 - np.exp(-((rho2 - loc_2)**2) / (2*sigma_ray2**2))

# Rice
#from scipy.integrate import quad from scipy.special import iv  # iv(nu, x) = I_nu(x) #cdf_rice_manual = np.zeros(len(rho)) for ii in range(len(rho)):
#def Qv(a,b,v):    return x * (x/a)**(v-1) * np.exp(-(x**2+a**2)/2) * iv(v-1, a*x)
import marcumq
#1. Parâmetros
var_rho2_2 = np.var((rho2)**2)
m2 = 1/var_rho2_2
k2 = np.sqrt(m2**2-m2)/(m2 - np.sqrt(m2**2-m2))
# 2. Calcular CDF Rice
v = 1
a_2 = np.sqrt(2*k2)
b_2 = np.sqrt(2*(1+k2))*rho2 # variável de Rice em função de rho
Q1_2 = marcumq.marcumq(v, a_2, b_2)
cdf_rice_manual2 = 1 - Q1_2

# Nakagami -m
from scipy.special import gamma, gammaincc
#2. Calcular CDF Nakagami
cdf_nakagami_manual2 = 1 - gammaincc(m2, m2 * rho2**2)

plt.figure(figsize=(10, 6))
plt.plot(x2, empirical_cdf2, 'k', lw=2, label='CDF Empírica (Medidas)')
plt.plot(x2, cdf_rayleigh_manual2,  '--', color ='steelblue', lw=2, label=f'Rayleigh\nσ={sigma_ray2:.3f}')
plt.plot(x2, cdf_rice_manual2,  '--', color ='orange', lw=1.5, label=f'Rice\nk={k2:.3f}')
plt.plot(x2, cdf_nakagami_manual2, '--', color = 'green', lw=2, label=f'Nakagami\nm={m2:.3f}')
plt.xlabel(r'$|r_2(t_i)|$')
plt.ylabel('Função Distribuição Cumulativa (CDF)')
plt.title('Ajuste de Distribuições: Rayleigh, Rice e Nakagami')
plt.legend()
plt.grid(True)
plt.show()

"""Rayleigh:
* Parâmetros idênticos obtidos.
* O desvio padrão obtido para o modelo de Rayleigh, $\sigma = 0,118$, é resultado do deslocamento da distribuição em $\mathrm{loc} = 0,84$ ($\mathrm{min}\{r(t_i)\}$).

Rice:
* É preciso converter parâmetros da biblioteca.
* Ajuste da biblioteca stats ($\mathrm{loc} =  0$) obteve $k = 1003,09$, enquanto o valor calculado foi $k = 999,74$. Descreve a relação entre a potência do sinal direto e sinal de multipercurso.

Nakagami:
* Ajuste da biblioteca stats ($\mathrm{loc} =  0$) obteve $m = 502,30$, enquanto o valor calculado foi $m = 500,62$. Descreve situação de desvanecimento fraco, com forte sinal direto.

### **8) Criar rotina para gerar amostras de desvanecimento para as 3 distribuições e mostrar exemplos.**
"""

import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# 1. Definir os parâmetros ajustados
params_rayleigh = (0.9105, 0.0651)      # (loc, scale)
params_rice = (44.79, 0, 0.0223)        # (b, loc, scale)
params_nakagami = (502.2991, 0, 1.0002) # (m, loc, scale)

n_samples = 10000

# 2. Gerar amostras artificiais
R_rayleigh = stats.rayleigh.rvs(loc=params_rayleigh[0], scale=params_rayleigh[1], size=n_samples)
R_rice = stats.rice.rvs(params_rice[0], loc=params_rice[1], scale=params_rice[2], size=n_samples)
R_nakagami = stats.nakagami.rvs(params_nakagami[0], loc=params_nakagami[1], scale=params_nakagami[2], size=n_samples)

print(f"Rayleigh: scale={params_rayleigh[1]:.4f}")
print(f"Rice: b={params_rice[0]:.2f}, scale={params_rice[2]:.4f}")
print(f"Nakagami: m={params_nakagami[0]:.1f}, scale={params_nakagami[2]:.4f}")

# 3. Plotar Histogramas com PDF teórica + CDFs
plt.figure(figsize=(14, 10))

# --- Rayleigh ---
plt.subplot(3, 2, 1)
plt.hist(R_rayleigh, bins=100, density=True, alpha=0.7, color='lightblue', edgecolor='black', label='Histograma')
x_pdf = np.linspace(R_rayleigh.min(), R_rayleigh.max(), 500)
pdf_theo = stats.rayleigh.pdf(x_pdf, loc=params_rayleigh[0], scale=params_rayleigh[1])
plt.plot(x_pdf, pdf_theo, 'r--', lw=2, label='PDF (stats)')
plt.title('Rayleigh – Histograma + PDF')
plt.xlabel('|r(t)|')
plt.ylabel('Densidade')
plt.legend()
plt.grid(True)

plt.subplot(3, 2, 2)
x = np.sort(R_rayleigh)
cdf_emp = np.arange(1, len(x)+1) / len(x)
cdf_theo = stats.rayleigh.cdf(x, loc=params_rayleigh[0], scale=params_rayleigh[1])
plt.plot(x, cdf_emp, 'b-', label='CDF "empírica"')
plt.plot(x, cdf_theo, 'r--', label='CDF (stats)')
plt.title('Rayleigh – CDF')
plt.xlabel('|r(t)|')
plt.ylabel('CDF')
plt.legend()
plt.grid(True)

# --- Rice ---
plt.subplot(3, 2, 3)
plt.hist(R_rice, bins=100, density=True, alpha=0.7, color='lightgreen', edgecolor='black', label='Histograma')
x_pdf = np.linspace(R_rice.min(), R_rice.max(), 500)
pdf_theo = stats.rice.pdf(x_pdf, params_rice[0], loc=params_rice[1], scale=params_rice[2])
plt.plot(x_pdf, pdf_theo, 'r--', lw=2, label='PDF (stats)')
plt.title('Rice – Histograma + PDF')
plt.xlabel('|r(t)|')
plt.ylabel('Densidade')
plt.legend()
plt.grid(True)

plt.subplot(3, 2, 4)
x = np.sort(R_rice)
cdf_emp = np.arange(1, len(x)+1) / len(x)
cdf_theo = stats.rice.cdf(x, params_rice[0], loc=params_rice[1], scale=params_rice[2])
plt.plot(x, cdf_emp, 'b-', label='CDF "empírica"')
plt.plot(x, cdf_theo, 'r--', label='CDF (stats)')
plt.title('Rice – CDF')
plt.xlabel('|r(t)|')
plt.ylabel('CDF')
plt.legend()
plt.grid(True)

# --- Nakagami ---
plt.subplot(3, 2, 5)
plt.hist(R_nakagami, bins=100, density=True, alpha=0.7, color='lightcoral', edgecolor='black', label='Histograma')
x_pdf = np.linspace(R_nakagami.min(), R_nakagami.max(), 500)
pdf_theo = stats.nakagami.pdf(x_pdf, params_nakagami[0], loc=params_nakagami[1], scale=params_nakagami[2])
plt.plot(x_pdf, pdf_theo, 'r--', lw=2, label='PDF (stats)')
plt.title('Nakagami – Histograma + PDF')
plt.xlabel('|r(t)|')
plt.ylabel('Densidade')
plt.legend()
plt.grid(True)

plt.subplot(3, 2, 6)
x = np.sort(R_nakagami)
cdf_emp = np.arange(1, len(x)+1) / len(x)
cdf_theo = stats.nakagami.cdf(x, params_nakagami[0], loc=params_nakagami[1], scale=params_nakagami[2])
plt.plot(x, cdf_emp, 'b-', label='CDF "empírica"')
plt.plot(x, cdf_theo, 'r--', label='CDF (stats)')
plt.title('Nakagami – CDF')
plt.xlabel('|r(t)|')
plt.ylabel('CDF')
plt.legend()
plt.grid(True)

plt.tight_layout()
plt.show()

"""## **Parte II: Encontrar parâmetros de caracterização do canal**

---

### **1) Plotar o Power Delay Profile (PDP) dos ambiente a partir da média de todos as CIRs.**

#### **8 taps**
"""

# Calcular o PDP: média dos quadrados por delay (ao longo das N medições)
PDP_1 = np.mean(data_array_0, axis=0)  #
PDP_dB_1 = 10*np.log10(PDP_1/np.max(PDP_1))
tau_1 = df_0.columns.values.astype(float)
# Plotar
plt.figure(figsize=(10, 6))
plt.plot(tau_1, PDP_dB_1,'-o')
#plt.ylabel(r'$\langle |h_1(\tau)|^2 \rangle$ (dB)')
#plt.ylabel(r'${\langle |h_1(\tau)|^2 \rangle}\,/\,{\max |h|^2}$ (dB)')
plt.ylabel(r'Média da potência normalizada (dB)')
plt.xlabel(r'$\tau$ (ns)')
plt.title('Power Delay Profile (PDP) - 8 taps')
plt.grid(True)
plt.show()

"""#### **20 taps**"""

# Calcular o PDP: média dos quadrados por delay (ao longo das N medições)
PDP_2 = np.mean(data_array_1, axis=0)  # shape: (L,)
PDP_dB_2 = 10*np.log10(PDP_2/np.max(PDP_2))
tau_2 = df_1.columns.values.astype(float)
# Plotar
plt.figure(figsize=(10, 6))
plt.plot(tau_2,PDP_dB_2,'-o')
#plt.ylabel(r'$\langle |R_2(\tau)|^2 \rangle$')
plt.ylabel(r'Média da potência normalizada (dB) - 20 taps')
plt.xlabel(r'$\tau$ (ns)')
plt.title('Power Delay Profile (PDP)')
plt.grid(True)
plt.show()

tau_2

"""### **2) A partir do PDP calcular RMS Delay Spread, Maximum Excess Delay e Mean Excess Delay.**

#### **8 taps**
"""

"""Caso interpolação adequada, usar:
tau = tau_1
PDP_dB = PDP_1_dB
tau_interp = np.linspace(tau[0], tau[len(tau)-1],1000)
PDP_dB_interp = np.interp(tau_interp, tau, PDP_dB)

ind_PDP_dB = np.argsort(PDP_dB)
max_2_PDP_dB = PDP_dB_1[ind_PDP_dB[-2]]
ind_tau_x = np.argmin(np.abs(PDP_dB_interp - max_2_PDP_dB))
tau1_x = tau_interp[ind_tau_x]"""

# Garantir que os arrays sejam float64 para evitar erros numéricos
tau = np.array(tau_1, dtype=np.float64)
PDP = np.array(PDP_1, dtype=np.float64)

# Remover valores nulos ou negativos (por segurança)
valid = (PDP > 0) & np.isfinite(PDP)
tau = tau[valid]
PDP_1 = PDP[valid]

# 1. Mean Excess Delay
mean_excess_delay = np.sum(tau * PDP_1) / np.sum(PDP_1)

# 2. RMS Delay Spread
# Calcular média do quadrado do atraso
mean_tau_squared = np.sum(tau**2 * PDP_1) / np.sum(PDP_1)
# RMS Delay Spread
rms_delay_spread = np.sqrt(mean_tau_squared - mean_excess_delay**2)

# 3. Maximum Excess Delay (com limiar de -X dB)
ind_PDP = np.argsort(PDP)
X = PDP[ind_PDP[-2]] # 2º máximo observado no gráfico, tempo maior que a média de atraso em excesso e a partir do qual a potência do sinal de caminho múltiplo cai para X = -0,4 dB abaixo do máximo
PDP_max = np.max(PDP)  # Valor máximo do PDP
limiar_db = 10*np.log10(X/PDP_max)  # Limiar em dB (conforme observado no gráfico)
limiar_linear = PDP_max * 10**(limiar_db / 10)  # Converter dB para escala linear

# Encontrar o índice do último ponto acima do limiar
indices_acima_limiar = np.where(PDP >= limiar_linear)[0]
if len(indices_acima_limiar) > 0:
    max_excess_delay = tau[indices_acima_limiar[-1]]  # Último ponto acima do limiar
else:
    max_excess_delay = np.nan  # Não há pontos acima do limiar

# Exibir resultados
print(f"Mean Excess Delay: {mean_excess_delay:.3f} ns")
print(f"RMS Delay Spread:  {rms_delay_spread:.3f} ns")
print(f"Maximum Excess Delay ({limiar_db:.3f} dB): {max_excess_delay:.3f} ns")

"""#### **20 taps**"""

import numpy as np

tau = tau_2
PDP = PDP_2

# 1. Mean Excess Delay
mean_excess_delay = np.sum(tau * PDP) / np.sum(PDP)

# 2. RMS Delay Spread
# Calcular média do quadrado do atraso
mean_tau_squared = np.sum(tau**2 * PDP) / np.sum(PDP)
# RMS Delay Spread
rms_delay_spread = np.sqrt(mean_tau_squared - mean_excess_delay**2)

# 3. Maximum Excess Delay (com limiar de -X dB)
ind_PDP = np.argsort(PDP)
X = PDP[ind_PDP[-4]] # 4º máximo observado no gráfico, tempo maior que a média de atraso em excesso e a partir do qual a potência do sinal de caminho múltiplo cai para X = -0,4 dB abaixo do máximo
PDP_max = np.max(PDP)  # Valor máximo do PDP
limiar_db = 10*np.log10(X/PDP_max)  # Limiar em dB (conforme observado no gráfico)
limiar_linear = PDP_max * 10**(limiar_db / 10)  # Converter dB para escala linear

# Encontrar o índice do último ponto acima do limiar
indices_acima_limiar = np.where(PDP >= limiar_linear)[0]
if len(indices_acima_limiar) > 0:
    max_excess_delay = tau[indices_acima_limiar[-1]]  # Último ponto acima do limiar
else:
    max_excess_delay = np.nan  # Não há pontos acima do limiar

# Exibir resultados
print(f"Mean Excess Delay: {mean_excess_delay:.3f} ns")
print(f"RMS Delay Spread:  {rms_delay_spread:.3f} ns")
print(f"Maximum Excess Delay ({limiar_db:.3f} dB): {max_excess_delay:.3f} ns")

"""### **3) Gerar plot para um subconjunto de CIRs e montar animação com a variação da CIR.**"""

from google.colab import drive
drive.mount('/content/drive')

"""#### **8 taps**"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

# Dados
tau = df_0.columns.values.astype(float)
CIRs = data_array_0

# --- Selecionar subconjunto de frames ---
num_frames = 100  # Número de frames na animação
indices = np.linspace(0, len(CIRs)-1, num_frames, dtype=int)  # Amostra uniforme

# Configuração do plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_xlabel(r'$\tau$ (ns)')
ax.set_ylabel('Amplitude normalizada')
ax.set_title(f'CIR 8 taps - Frame 1/{num_frames}')
ax.grid(True, alpha=0.3)

line, = ax.plot(tau, CIRs[indices[0]], lw=2, color='blue', label=r'CIR($t_i$)')
ax.legend()
ax.set_xlim(tau.min(), tau.max())
ax.set_ylim(0, np.max(CIRs) * 1.1)

# Função de atualização
def update(frame):
    idx = indices[frame]
    line.set_ydata(CIRs[idx])
    ax.set_title(f'CIR 8 taps - Frame {frame + 1}/{num_frames}')
    return line,

# Criar animação
ani = animation.FuncAnimation(
    fig=fig,
    func=update,
    frames=num_frames,
    interval=200,
    repeat=True,
    blit=True
)

# Salvar 100 frames
ani.save('cir8taps_animation.gif', writer='pillow', fps=5)

#ani.save('cir8taps_animation.mp4', writer='ffmpeg', fps=5, dpi=150)

from PIL import Image
import os
from google.colab import files
import zipfile

# PASSO 1: Criar pasta e converter GIF
if not os.path.exists('Frames'):
    os.makedirs('Frames')
    print("Pasta 'Frames' criada")

try:
    gif = Image.open('cir8taps_animation.gif')

    frames = []
    for frame in range(gif.n_frames):
        gif.seek(frame)
        frames.append(gif.copy())

    # Salvar frames
    for i, frame in enumerate(frames):
        frame.save(f'Frames/cir8taps_frame_{i:02d}.png')

    print(f"Convertido: {len(frames)} frames")
    print(f"Comando LaTeX: \\animategraphics[loop,controls]{{10}}{{Frames/cir8taps_frame_}}{{0}}{{{len(frames)-1}}}")
    # PASSO 2: Baixar pasta
    # print("\nPreparando download...")
    # with zipfile.ZipFile('Frames.zip', 'w') as zipf:
    #     for file in os.listdir('Frames'):
    #         zipf.write(f'Frames/{file}')

    #files.download('Frames.zip')
    #print("Download iniciado! Verifique sua pasta de downloads")

except FileNotFoundError:
    print("Erro: 'cir8taps_animation.gif' não encontrado")
    print(" Faça upload do GIF para o Colab primeiro")
except Exception as e:
    print(f"Erro: {e}")

"""### **4) Comparar procedimento para os dois arquivos e analisar a influência da resolução da CIR.**

#### **20 taps**
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

# Dados
tau = df_1.columns.values.astype(float)
CIRs = data_array_1

# --- Selecionar subconjunto de frames ---
num_frames = 100  # Número de frames na animação
indices = np.linspace(0, len(CIRs)-1, num_frames, dtype=int)  # Amostra uniforme

# Configuração do plot
fig, ax = plt.subplots(figsize=(10, 6))
ax.set_xlabel(r'$\tau$ (ns)')
ax.set_ylabel('Amplitude normalizada')
ax.set_title(f'CIR 20 taps - Frame 1/{num_frames}')
ax.grid(True, alpha=0.3)

line, = ax.plot(tau, CIRs[indices[0]], lw=2, color='blue', label=r'CIR($t_i$)')
ax.legend()
ax.set_xlim(tau.min(), tau.max())
ax.set_ylim(0, np.max(CIRs) * 1.1)

# Função de atualização
def update(frame):
    idx = indices[frame]
    line.set_ydata(CIRs[idx])
    ax.set_title(f'CIR 20 taps - Frame {frame + 1}/{num_frames}')
    return line,

# Criar animação
ani = animation.FuncAnimation(
    fig=fig,
    func=update,
    frames=num_frames,
    interval=200,
    repeat=True,
    blit=True
)

# Salvar 100 frames
ani.save('cir20taps_animation.gif', writer='pillow', fps=5)
#ani.save('cir20taps_animation.mp4', writer='ffmpeg', fps=5, dpi=150)

from PIL import Image
import os
from google.colab import files
import zipfile

# PASSO 1: Criar pasta e converter GIF
if not os.path.exists('Frames'):
    os.makedirs('Frames')
    print("Pasta 'Frames' criada")

try:
    gif = Image.open('cir20taps_animation.gif')

    frames = []
    for frame in range(gif.n_frames):
        gif.seek(frame)
        frames.append(gif.copy())

    # Salvar frames
    for i, frame in enumerate(frames):
        frame.save(f'Frames/cir20taps_frame_{i:02d}.png')

    print(f"Convertido: {len(frames)} frames")
    print(f"Comando LaTeX: \\animategraphics[loop,controls]{{10}}{{Frames/cir20çtaps_frame_}}{{0}}{{{len(frames)-1}}}")

    # PASSO 2: Baixar pasta
    print("\nPreparando download...")
    with zipfile.ZipFile('Frames.zip', 'w') as zipf:
        for file in os.listdir('Frames'):
            zipf.write(f'Frames/{file}')

    files.download('Frames.zip')
    print("Download iniciado! Verifique sua pasta de downloads")

except FileNotFoundError:
    print("Erro: 'cir20taps_animation.gif' não encontrado")
    print(" Faça upload do GIF para o Colab primeiro")
except Exception as e:
    print(f"Erro: {e}")

"""## **Parte III: Gerar modelo Saleh-Valenzuela (SV)**

### **1) Criar rotina para gerar CIRs a partir de parâmetros do modelo SV. Mostrar alguns exemplos gerados a partir de diferentes valores dos parâmetros e o que acontece quando cada parâmetro é variado individualmente.**

O modelo SV é estocástico e representa a dispersão temporal de um canal de múltiplos percursos.
Ele é amplamente usado para canais de rádio em interiores e ultra-wideband.

O modelo assume:

Clusters de ecos chegam aleatoriamente (processo de Poisson com taxa Λ);

Dentro de cada cluster, raios individuais também chegam de forma aleatória (taxa λ);

A potência média de cada caminho decai exponencialmente:

$$ E[|a_{k,l}^2|] = \Omega_0 e^{-T_l/\Gamma} e^{-\tau_{k,l}/\gamma}$$

onde $T_l$ é o atraso do cluster $l$ e $\tau_{k,l}$ o atraso relativo do raio k dentro dele;

As amplitudes podem seguir Nakagami, Rician ou Rayleigh.

#### ***SV CIR(t)***
"""

# Saleh–Valenzuela
def generate_SV_CIR_corrected(Lambda=1/30e-9, lambda_ray=1/5e-9,
                             Gamma=30e-9, gamma=10e-9,
                             beta0=1.0, max_time=200e-9, max_clusters=10):
    """
    Gera resposta impulsiva h(t) segundo modelo Saleh-Valenzuela.
    """
    np.random.seed(31415)

    # 1. Gera tempos de chegada dos clusters (processo Poisson com taxa Lambda)
    T = [0.0]  # Primeiro cluster em t=0
    current_time = 0.0

    for _ in range(max_clusters - 1):
        delta_T = np.random.exponential(1/Lambda)
        current_time += delta_T
        if current_time > max_time:
            break
        T.append(current_time)

    # 2. Para cada cluster, gera raios dentro dele (processo Poisson com taxa lambda_ray)
    CIR_time, CIR_amp = [], []

    for Tl in T:
        tau = [0.0]  # Primeiro raio em tau=0 dentro do cluster
        current_tau = 0.0
        max_rays = 20

        for _ in range(max_rays - 1):
            delta_tau = np.random.exponential(1/lambda_ray)
            current_tau += delta_tau
            if current_tau > max_time:
                break
            tau.append(current_tau)

        # 3. Amplitude com decaimento duplo CORRETO e fase aleatória
        for tau_k in tau:
            power = beta0**2 * np.exp(-Tl/Gamma) * np.exp(-tau_k/gamma)
            amp = np.sqrt(power) * np.exp(1j * 2 * np.pi * np.random.rand())

            CIR_time.append(Tl + tau_k)
            CIR_amp.append(amp)

    return np.array(CIR_time), np.array(CIR_amp), T

# =====================================================
# Função auxiliar para plotar 4 variações em subplots
# =====================================================
def plot_variations_corrected(param_name, values, params):
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    axes = axes.flatten()

    # Define uma paleta de 4 cores distintas
    colors = ['darkblue', 'darkgreen', 'darkred', 'darkorange']

    for i, val in enumerate(values):
        local_params = params.copy()
        local_params[param_name] = val
        t, a, cluster_times = generate_SV_CIR_corrected(**local_params)

        if len(t) > 0:
            # Usa cor diferente para CADA subplot (i-ésimo), independente do parâmetro
            markerline, stemlines, baseline = axes[i].stem(t * 1e9, np.abs(a))
            plt.setp(markerline, color=colors[i], alpha=0.6, markersize=5)
            plt.setp(stemlines, color=colors[i], alpha=0.6)

            # Marca os tempos dos clusters com linhas verticais (mantém vermelho tracejado)
            for ct in cluster_times:
                axes[i].axvline(x=ct * 1e9, color='black', linestyle='--', alpha=0.5, linewidth=1)

        # Títulos informativos
        if param_name == 'Gamma':
            #scale_info = f"\nTl/Γ ≈ {cluster_times[-1]/val:.1f}" if len(cluster_times) > 0 else ""
            axes[i].set_title(f"$\\Gamma$ = {val*1e9:.1f} ns\nDecaimento inter-cluster")
        elif param_name == 'gamma':
            axes[i].set_title(f"$\\gamma$ = {val*1e9:.1f} ns\nDecaimento intra-cluster")
        elif param_name == 'Lambda':
            axes[i].set_title(f"$1/\\Lambda$ = {1/val*1e9:.1f} ns\nTempo médio entre clusters")
        elif param_name == 'lambda_ray':
            axes[i].set_title(f"$1/\\lambda_{{\\text{{ray}}}}$ = {1/val*1e9:.1f} ns\nTempo médio entre raios")
        else:
            axes[i].set_title(f"{param_name} = {val}")
        axes[i].set_xlabel("Tempo [ns]")
        axes[i].set_ylabel("Amplitude")
        axes[i].grid(True, alpha=0.3)
        axes[i].set_xlim(0, params.get('max_time', 200e-9) * 1e9)

    plt.suptitle(f"Efeito da variação de {param_name} - Modelo SV", fontsize=14, weight='bold')
    plt.tight_layout(rect=[0, 0, 1, 1])
    plt.show()

# =====================================================
# Parâmetros fixos de base CORRETOS
# =====================================================
# MUDANÇA: Ajustar Gamma para escala consistente
params_base = dict(Lambda=1/60e-9,      # ~1 cluster a cada 60ns
                   lambda_ray=1/10e-9,  # ~1 raio a cada 10ns dentro do cluster
                   Gamma=100e-9,        # MUDANÇA: Gamma maior para escala consistente
                   gamma=50e-9,         # decaimento raios: 10ns
                   beta0=1.0,
                   max_time=400e-9)     # MUDANÇA: Janela maior para ver efeito

print("=== Variação de Γ (Gamma) - Decaimento dos Clusters ===")
print("NOTA: Gamma ajustado para escala consistente com tempos dos clusters")
Gamma_vals = [100e-9, 200e-9, 400e-9, 800e-9] # Valores de Gamma são elevados para observar a variação desse parâmetro
plot_variations_corrected("Gamma", Gamma_vals, params_base)

print("=== Variação de γ (gamma) - Decaimento dos Raios ===")
gamma_vals = [50e-9, 100e-9, 150e-9, 200e-9]
plot_variations_corrected("gamma", gamma_vals, params_base)

print("=== Variação de Λ (Lambda) - Taxa de Clusters ===")
Lambda_vals = [1/30e-9, 1/60e-9, 1/100e-9, 1/150e-9]
plot_variations_corrected("Lambda", Lambda_vals, params_base)

print("=== Variação de λ (lambda_ray) - Taxa de Raios ===")
lambda_ray_vals = [1/5e-9, 1/10e-9, 1/20e-9, 1/40e-9]
plot_variations_corrected("lambda_ray", lambda_ray_vals, params_base)